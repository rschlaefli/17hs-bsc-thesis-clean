import numpy as np

from ModelHelpers import ModelHelpers
from ModelBASEv2B import ModelBASEv2B


class ModelERAv3B(ModelBASEv2B):
    """ Version 3B of ERA-based LSTM model """

    def __init__(self, version='E3b', cache_id=None):
        super().__init__(version, cache_id=cache_id)

    @staticmethod
    def train_test_split(datasets,
                         prediction_ts,
                         onset_ts,
                         true_offset,
                         years=range(1979, 2018),
                         years_train=range(1979, 2010),
                         years_dev=range(2010, 2013),
                         years_test=range(2013, 2018)):
        """
        Prepare data to be in a digestible format for the model

        :datasets: List of datasets to use as features
        :outcomes: Outcomes as generated by the base model

        :return:
        """

        # generate outcomes
        outcomes_train = ModelHelpers.generate_outcomes(prediction_ts, onset_ts, years_train, numerical=True, sequence=True, true_offset=true_offset)
        outcomes_rest = ModelHelpers.generate_outcomes(prediction_ts, onset_ts, [i for j in (years_dev, years_test) for i in j], numerical=True, sequence=True)
        print(outcomes_train, outcomes_rest)

        # datasets = ModelHelpers.augment_data(datasets, prediction_ts, years)

        # unstack the entire dataset
        # => bring into matrix form with lat/lon on axes
        # unstacked = ModelHelpers.unstack_all(datasets, years)
        # unstacked = ModelHelpers.prepare_datasets(years, datasets, prediction_ts)

        # print(unstacked[1995][0][0])
        # print(f'> unstacked: {unstacked[1995].shape!s}')

        # generate training data
        X_train = ModelHelpers.prepare_datasets(years_train, datasets, prediction_ts, true_offset=true_offset)
        # X_train = ModelHelpers.reshape_years([unstacked[year] for year in years_train], num_channels=len(datasets))
        y_train = ModelHelpers.stack_outcomes(outcomes_train, years_train, augmented=True)
        print(X_train[0][0][0])
        print('> X_train', X_train.shape, 'y_train', y_train.shape)

        X_train = ModelHelpers.normalize_channels(X_train)

        # generate test data
        X_test = ModelHelpers.prepare_datasets(years_test, datasets, prediction_ts)
        # X_test = ModelHelpers.reshape_years([unstacked[year] for year in years_test], num_channels=len(datasets))
        y_test = ModelHelpers.stack_outcomes(outcomes_rest, years_test, augmented=True)
        print(X_test[0][0][0])
        print('> X_test', X_test.shape, 'y_test', y_test.shape)

        X_test = ModelHelpers.normalize_channels(X_test)


        if years_dev:
            # X_dev = ModelHelpers.reshape_years([unstacked[year] for year in years_dev], num_channels=len(datasets))
            X_dev = ModelHelpers.prepare_datasets(years_dev, datasets, prediction_ts)
            y_dev = ModelHelpers.stack_outcomes(outcomes_rest, years_dev, augmented=True)
            print(X_dev.shape)
            print('> X_dev', X_dev.shape, 'y_dev', y_dev.shape)

            X_dev = ModelHelpers.normalize_channels(X_dev)

            return X_train, y_train, X_test, y_test, X_dev, y_dev

        return X_train, y_train, X_test, y_test, None, None
